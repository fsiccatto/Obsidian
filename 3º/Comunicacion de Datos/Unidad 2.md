# Teor√≠a de la Informaci√≥n
> [!info] Objetivo
> - Se ocupa de la medici√≥n de la informaci√≥n
> - La capacidad de los sistemas para transmitir y procesar informaci√≥n
> - Garantiza el transporte masivo de datos sin merma de la calidad
> - No perder ninguna informaci√≥n transmitida
## Transmisi√≥n de la Informaci√≥n
- Teor√≠a de la informaci√≥n: nace con la necesidad de saber la capacidad de los Sistemas de Comunicaciones de llevar informaci√≥n. Se centra en las se√±ales el√©ctricas y su contenido de informaci√≥n.
- Fuentes: es todo aquello que emite mensajes
	- Estructurada: posee cierto nivel de redundancia.
	- No estructurada: los mensajes no se pueden comprimir sin que haya una p√©rdida de mensaje.
- Mensaje: datos enviados. Conjunto de 0 y 1.
- C√≥digo: conjunto de 1 y 0 que se usan para representar un cierto mensaje. Informaci√≥n contenida en el mensaje $S$, es la *cantidad m√≠nima de bits para codificar un mensaje*.
- Informaci√≥n: es simplemente lo que produce la fuente para transferir al usuario. Es *proporcional a la cantidad de bits*.
	- La ocurrencia de mensajes de alta probabilidad de aparici√≥n aporta menos informaci√≥n que la ocurrencia de mensajes menos probables. A medida que la probabilidad de ocurrencia del mensaje sea mayor, menor informaci√≥n contendr√° el mismo.
### Cantidad de Informaci√≥n
La cantidad de informaci√≥n esta relacionada con probabilidad de ocurrencia $p$, dado por:
$$ I = \log_{n}\left( \frac{1}{p} \right)$$

| Sistemas | Informaci√≥n  |
| :------- | :----------- |
| n = 2    | I en bits    |
| n = 10   | I en Hartley |
| n = e    | I en nat     |
### Entrop√≠a de la Fuente
El nivel de informaci√≥n de una fuente se puede medir seg√∫n la entrop√≠a de la misma.
La entrop√≠a de la fuente es la base de la compresi√≥n de datos.
Para codificar los mensajes de una fuente se utilizar√°: 
	Menor cantidad de bits ‚Üí para los mensajes m√°s probables
	Mayor cantidad de bits ‚Üí para los mensajes menos probables
$$H = \sum_{j=1}^mp_{j}I_{j} = \sum_{j=1}^mp_{j}\log_{2}\left( \frac{1}{p_{j}} \right)$$
- La entrop√≠a de la fuente determina la *compresi√≥n que podemos aplicar*.
- Se demuestra que *no es posible comprimir un mensaje m√°s all√° de su entrop√≠a* (Shannon).
- El **objetivo** de la compresi√≥n de datos es encontrar los $ùë∞_{j}$ que minimizan a $H$.
- Los $ùë∞_{j}$ se determinan en funci√≥n de las $ùíë_{j}$ , pues la longitud de los c√≥digos dependen de la probabilidad de ocurrencia de los mismos.
### Ancho de Banda
Es una caracter√≠sitica importante ya que **determina la capacidad del canal**, para la transferencia de informaci√≥n dentro de una rango de frecuencias.
$$ B = f_{2} - f_{1} \text{ [Hz]}$$
![[imgs/ancho de banda.png]]
### Capacidad de Canal
##### Capacidad de Canal SIN Ruido - Nyquist
Nyquist plante√≥ la existencia de un l√≠mite en la capacidad de un canal ideal (sin ruido ni distorsiones) de ancho de banda finito. Establece que la *velocidad m√°xima de transmisi√≥n de datos* en bps viene limitada por la siguiente expresi√≥n:
$$C=2B\log_{2}(M)$$
C: capacidad de canal en bps
B: ancho de banda en Hz
M: n√∫mero de niveles posible de la se√±al -> corresponde al n√∫mero de se√±ales diferentes que sale de un modulador digital
- Si n = 2 entonces: $M = 2^N \implies C = 2B$

> [!caution] Nota
> Para aumentar la capacidad de canal se deben incrementar los niveles de tensi√≥n, M.
> Cuanto mayor es la velocidad de transmisi√≥n, mayor es el da√±o que puede ocasionar el ruido.
> No representa los efectos causados por el ruido, en un canal de comunicaciones real.
##### Capacidad de Canal CON Ruido - Shannon
El teorema de Shannon es:
$$C=B\log_{2}\left( 1+ \frac{S}{N} \right)$$
C: velocidad m√°xima en bits por segundo
B: ancho de banda
S/N: relaci√≥n se√±al a ruido
Este es l√≠mite te√≥rico impuesto por el teorema de Shannon, porque nunca lo han igualado.
###### Aplicaciones
Cableado Estructurado
	![[imgs/cableado estructurado.png]]
Mejora continua en medios de transmisi√≥n
	Los medios de transmisi√≥n continuamente est√°n *aumentando las velocidades m√°ximas disponibles*, la forma en que lo consiguen es o bien *mejorando el ancho de banda o bien mejorando la relaci√≥n se√±al a ruido*.

> [!tldr] Comparaci√≥n Teorema de Shannon con Nyquist
> Comparando la capacidad del canal de Shannon con la tasa de informaci√≥n de Nyquist, podemos encontrar el n√∫mero eficaz de los niveles distinguibles o estados de modulaci√≥n M.
> $$2B\log_{2}(M) = B \log_{2}\left( 1+\frac{S}{N} \right)$$
> $$ M = \sqrt{ 1 + \frac{S}{N} }$$

# Se√±ales Anal√≥gicas y Digitales
## Se√±ales Anal√≥gicas
Las se√±ales anal√≥gicas son *continuas en tiempo y amplitud*. Representan variaciones f√≠sicas y se pueden describir como una *funci√≥n continua en un per√≠odo determinado*. Ejemplo com√∫n es la se√±al de audio en un disco de vinilo, donde las variaciones en la forma de la onda representan diferentes sonidos.
- Naturaleza Continua -> la SA no tiene interrupciones y fluye de forma constante.
- Representaci√≥n -> mediante una onda sinusoidal continua en funci√≥n del tiempo.
- Suceptibilidad al ruido -> son m√°s suceptibles a la interferencia y al ruido.
- Alacenamiento y transmisi√≥n -> pueden ser dif√≠ciles de almacenar y transmitir en comparaci√≥n con SD.
## Se√±ales Digitales
Las se√±ales digitales, por otro lado, tienen una *naturaleza discreta*. Se representan mediante una *serie de valores discretos*, t√≠picamente 0 y 1, y se transmiten en forma de pulsos. Ejemplo com√∫n es la m√∫sica en formato MP3, donde los datos se almacenan en forma digital.
- Naturaleza Discreta -> tiene valores definidos en puntos espec√≠ficos en el tiempo.
- Representaci√≥n -> mediante una serie de valores binarios (0 y 1).
- Resistencia a ruido -> son menos susceptibles al ruido y la interferencia.
- Almacenamiento y transmisi√≥n -> m√°s f√°ciles de almacenar y transmitir, manteniendo la calidad.
## Impacto Tecnol√≥gico
Depender√° de la aplicaci√≥n espec√≠fica, la necesidad de precisi√≥n, el entorno de transmisi√≥n y otros factores.
- Telecomunicaciones : Las se√±ales digitales han ganado prominencia en las telecomunicaciones debido a su resistencia al ruido y facilidad de transmisi√≥n . Esto ha llevado a una mayor calidad en las comunicaciones m√≥viles y por Internet.
- Audio y video: las se√±ales digitales permiten una mayor portabilidad y acceso en dispositivos modernos.
- Medicina : En el campo m√©dico, las se√±ales digitales facilitan la captura y el an√°lisis de datos.
- Automatizaci√≥n Industrial : La utilizaci√≥n de se√±ales digitales en la automatizaci√≥n industrial permite un control preciso y en tiempo real de maquinarias y procesos.
# Banda Base
Banda de frecuencias producidas por un transductor. Ejemplo: micr√≥fono, tel√©grafo.
## Tipos de Banda Base
![[imgs/tipos de banda base.png]]

| Banda Base               | Banda Ancha                  |     |
| :----------------------- | :--------------------------- | --- |
| Transmite solo una se√±al | Transmite m√°s de una se√±al   |     |
| No es decodificada       | Es decodificada y regenerada |     |
| Recursos limitados       | Recursos amplios             |     |
| Activo / Inactivo        | Siempre activo               |     |
![[imgs/banda ancha vs banda base.png]]